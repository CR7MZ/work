#### 项目名称：

​				文件压缩

#### 做该项目的原因：

​				由于学习了Huffman树以及哈希结构，因此学校老师带领我们做的这个的项目。目的是让我			们更加深入的理解Huffman树的性质，以及学习项目是如何从无到有的，并且扩展一些新的知			识。

#### 项目实现：

##### 				项目原理：

​							该项目是基于GZIP算法的思想来实现一个简单地文件压缩功能的。

##### 				项目流程：

###### 							第一阶段：

​											根据LZ77算法的变形，对文件进行语句重复上的压缩，也就是将重复的语句											替换为更为简短的长度距离对。在第一阶段的压缩过程中，实际上使用了一											个64K大小的窗口来保存待压缩数据，我们将这个窗口分为两部分，每部分											大小为32K。并且窗口中有两部分内容，分别是查找缓冲区、先行缓冲区，											查找缓冲区就是进行查重的区域，同样里面的数据也是压缩过的数据。而先											行缓冲区里是我们待压缩的数据。并且我们规定最短的匹配长度为3个字											符，因此压缩的时候是取先行缓冲区的第一个字符与其后面两个字符组成一											个字符串，之后去查找缓冲区中找匹配，找到了则替换成长度距离对。随着											压缩的不断进行，查找缓冲区不断增大，先行缓冲区不断减少，我们规定当											查找缓冲区的大小为32K时将不再增大。先行缓冲区如果减小到一定的值，											那么说明需要更新窗口，将新的数据读入窗口中。

###### 							第二阶段：

​											利用Huffman树的性质，对LZ77压缩后的文件数据进行字节上的压缩。根据											统计文件中每个字符出现的次数，构建Huffman树。我们将树的左支路认为											是0，右支路认为是1，通过不断地由根结点递归找叶子结点的方式，获取每											一个字符的编码，保存起来。最后将待压缩的文件中的每个字符对应的编											码，按照字符出现的顺序写入写入字节中，如果字节写满则将此字节写入压											缩文件中，直到文件全部写完。

#### 项目问题及解决办法：

##### 				第一阶段问题：

​							1.如何高效的查找最长的匹配串

​											解决方法：想要高效的查找，第一时间想到的就是采用哈希的方式。因此，											这里的哈希表用的是一段连续的空间，分为两个部分，每个部分都为32K。											prev和head指针分别指向两部分起始位置，prev指向整个空间的开头，											head指向prev+32K的位置。可以将prev和head看成数组。head是用来保存											三个字符组成的字符串首字符在窗口中的索引，prev是用来解决哈希冲突											的。

​							2.如果找不到最长匹配串怎么办

​											解决方法：直接将该字符写入压缩文件中。

​							2.第一阶段压缩之后，我们没有办法区分已压缩文件中，原文数据和长度距离对。

​											解决方法：使用标记信息进行标记，也就是一段二进制码。每写入压缩文件											一个字符，同时标记这个字符的状态，0表示原文件字符，1表示该字符以及											后面的一个字符为长度距离对。

##### 				第二阶段问题：

​							1.构建Huffman树时，怎样可以快速的找到出现次数最小的两个字符。

​											解决方法：使用优先级队列来保存字符出现的次数。

​							2.在解压缩的时候，发现数据只解压了一半。因为二进制文件中可能会存在FF，而文								本文件的末尾就是用FF表示的，所以在解压缩时，我们如果用文本格式打开文件，								就有可能读到FF，造成文件解压了一半。

​											解决方法：使用二进制格式打开文件。

#### 项目的不足以及优化：

​				1.用Huffman进行压缩时，就牵扯到Huffman树，如果文件中的字符种类非常多，那么我们					的Huffman树就会非常大，这样树占的空间也会非常大。以及因为我们获取编码的方式是					使用递归的方式，因此获取编码的效率也会非常低。并且，我们解压缩是不断从根结点向					叶子结点遍历，所以也会影响解压缩的效率。

​				2.因为我们是需要解压缩的，所以Huffman压缩会将每个字符出现的次数一起存入压缩文件					中，供解压时使用。那么如果字符种类比较多，且出现的次数较为均匀，那么压缩文件中					光是保存的字符信息就占了一大半，严重影响压缩率。

​				优化：采用范式Huffman树来解决此问题。泛型Huffman树，并没有真正的构建树，而是使							用数组来模拟实现Huffman树。

#### 项目测试：

​			1.5M文件，能压缩到0.7M左右，用时0.5s左右，压缩率53%左右

​			3.2M文件，能压缩到1.5M左右，用时1s左右，压缩率53%左右

